# ğŸ¤– AI Models Comparison Platform

Una plataforma completa para comparar mÃºltiples modelos de LLM (Large Language Models) de forma concurrente, con evaluaciÃ³n automÃ¡tica y mÃ©tricas detalladas.

## âœ¨ CaracterÃ­sticas

### ğŸ¯ **Funcionalidades Principales**
- **ComparaciÃ³n Concurrente**: Ejecuta mÃºltiples modelos en paralelo usando `asyncio.gather`
- **EvaluaciÃ³n AutomÃ¡tica**: Sistema de evaluaciÃ³n basado en reconstrucciÃ³n de texto
- **MÃ©tricas Detalladas**: Scores de similitud, consistencia y compresiÃ³n
- **Interfaz Moderna**: DiseÃ±o inspirado en Cursor IDE + Stripe
- **Arquitectura Modular**: FÃ¡cil extensiÃ³n para nuevos mÃ³dulos

### ğŸ”§ **TecnologÃ­as**
- **Backend**: FastAPI + Pydantic + Uvicorn
- **Frontend**: Vanilla JavaScript + CSS Grid + Flexbox
- **LLM Providers**: OpenAI, Anthropic, Google
- **Concurrencia**: `asyncio.gather` para ejecuciÃ³n paralela
- **Deployment**: Vercel + Python

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- Python 3.8+
- API Keys de los proveedores de LLM

### InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/ai-models-comparison.git
cd ai-models-comparison
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env con tus API keys
```

5. **Ejecutar la aplicaciÃ³n**
```bash
python main.py
```

La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:8000`

## ğŸ”‘ ConfiguraciÃ³n de API Keys

Crea un archivo `.env` en la raÃ­z del proyecto:

```bash
# OpenAI
OPENAI_API_KEY=tu_openai_api_key_aqui

# Anthropic (opcional)
ANTHROPIC_API_KEY=tu_anthropic_api_key_aqui

# Google (opcional)
GOOGLE_API_KEY=tu_google_api_key_aqui

# ConfiguraciÃ³n del servidor
DEBUG=true
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO
```

## ğŸ“ Estructura del Proyecto

```
ai-models-comparison/
â”œâ”€â”€ app/                          # Backend FastAPI
â”‚   â”œâ”€â”€ llm/                      # MÃ³dulo LLM
â”‚   â”‚   â”œâ”€â”€ config.py             # ConfiguraciÃ³n LLM
â”‚   â”‚   â”œâ”€â”€ models.py              # Modelos Pydantic
â”‚   â”‚   â”œâ”€â”€ service.py             # Servicio LLM
â”‚   â”‚   â””â”€â”€ router.py              # Rutas API
â”‚   â”œâ”€â”€ summarization/             # MÃ³dulo Summarization
â”‚   â”‚   â”œâ”€â”€ config.py             # ConfiguraciÃ³n
â”‚   â”‚   â”œâ”€â”€ models.py              # Modelos
â”‚   â”‚   â”œâ”€â”€ service.py             # Servicio
â”‚   â”‚   â”œâ”€â”€ evaluator.py          # Evaluador
â”‚   â”‚   â””â”€â”€ router.py              # Rutas
â”‚   â””â”€â”€ config.py                  # ConfiguraciÃ³n global
â”œâ”€â”€ static/                        # Frontend
â”‚   â”œâ”€â”€ css/                       # Estilos
â”‚   â”‚   â”œâ”€â”€ themes/                # Temas (Cursor + Stripe)
â”‚   â”‚   â””â”€â”€ modules/                # Estilos por mÃ³dulo
â”‚   â””â”€â”€ js/                        # JavaScript
â”‚       â”œâ”€â”€ core/                  # Core frontend
â”‚       â””â”€â”€ modules/               # MÃ³dulos frontend
â”œâ”€â”€ templates/                     # Templates HTML
â”œâ”€â”€ main.py                        # Punto de entrada
â”œâ”€â”€ requirements.txt               # Dependencias
â””â”€â”€ README.md                      # Este archivo
```

## ğŸ¨ Arquitectura

### Backend (FastAPI)
- **Arquitectura Modular**: Cada funcionalidad en su propio mÃ³dulo
- **Concurrencia**: `asyncio.gather` para ejecuciÃ³n paralela
- **EvaluaciÃ³n**: Sistema de reconstrucciÃ³n de texto para evaluar resÃºmenes
- **API RESTful**: Endpoints bien documentados

### Frontend (Vanilla JS)
- **Modular**: JavaScript organizado por mÃ³dulos
- **Responsive**: CSS Grid + Flexbox
- **Tema**: Inspirado en Cursor IDE + Stripe
- **Estado**: GestiÃ³n de estado centralizada

## ğŸ”¬ Sistema de EvaluaciÃ³n

### MÃ©todo de ReconstrucciÃ³n
1. **GeneraciÃ³n**: Se generan 5 resÃºmenes por modelo
2. **ReconstrucciÃ³n**: Un modelo evaluador intenta reconstruir el texto original
3. **Similitud**: Se calcula la similitud Jaccard entre original y reconstruido
4. **CompresiÃ³n**: Bonus por resÃºmenes mÃ¡s cortos que mantengan informaciÃ³n
5. **Consistencia**: Mide la consistencia entre los 5 resÃºmenes

### MÃ©tricas
- **Similarity Score**: QuÃ© tan bien reconstruye el texto original
- **Compression Bonus**: Premio por compresiÃ³n eficiente
- **Consistency Score**: Consistencia entre mÃºltiples resÃºmenes
- **Execution Time**: Tiempo de ejecuciÃ³n por modelo

## ğŸš€ Deployment en Vercel

### 1. Preparar para Vercel

Crear `vercel.json`:
```json
{
  "version": 2,
  "builds": [
    {
      "src": "main.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "main.py"
    }
  ]
}
```

### 2. Variables de Entorno en Vercel
```bash
vercel env add OPENAI_API_KEY
vercel env add ANTHROPIC_API_KEY
vercel env add GOOGLE_API_KEY
```

### 3. Deploy
```bash
vercel --prod
```

## ğŸ“Š Uso de la AplicaciÃ³n

### 1. Dashboard
- **EstadÃ­sticas**: Modelos disponibles, proveedores activos
- **Acciones RÃ¡pidas**: NavegaciÃ³n a mÃ³dulos
- **Estado del Sistema**: Health check y configuraciÃ³n

### 2. Summarization Module
- **SelecciÃ³n de Modelos**: Filtros por proveedor, bÃºsqueda
- **ConfiguraciÃ³n LLM**: Temperature, tokens, top-p, top-k
- **Input de Texto**: Textarea con contador de palabras
- **ComparaciÃ³n**: Ejecuta modelos en paralelo
- **Resultados**: Scores, mÃ©tricas y resÃºmenes

### 3. Filtros y BÃºsqueda
- **Por Proveedor**: OpenAI, Google, Anthropic
- **BÃºsqueda**: Por nombre de modelo o proveedor
- **SelecciÃ³n Persistente**: Se mantiene al cambiar filtros

## ğŸ”§ API Endpoints

### LLM Module
- `GET /llm/models` - Lista modelos disponibles
- `GET /llm/config` - ConfiguraciÃ³n LLM
- `POST /llm/test/{model}` - Probar modelo especÃ­fico

### Summarization Module
- `POST /summarization/compare` - Comparar modelos
- `GET /summarization/config` - ConfiguraciÃ³n
- `POST /summarization/test` - Probar resumen simple

### Sistema
- `GET /health` - Health check
- `GET /` - Dashboard principal

## ğŸ§ª Testing

### Pruebas AutomÃ¡ticas
```bash
# Probar API
curl http://localhost:8000/health

# Probar modelos
curl http://localhost:8000/llm/models

# Probar resumen
curl -X POST "http://localhost:8000/summarization/test" \
  -d "text=Test text&model=gpt-3.5-turbo&max_words=20"
```

### Pruebas Manuales
1. **NavegaciÃ³n**: Dashboard â†’ Summarization
2. **SelecciÃ³n**: Filtrar y seleccionar modelos
3. **ComparaciÃ³n**: Texto + modelos seleccionados
4. **Resultados**: Verificar scores y mÃ©tricas

## ğŸ› ï¸ Desarrollo

### Agregar Nuevo MÃ³dulo
1. Crear directorio en `app/`
2. Implementar `config.py`, `models.py`, `service.py`, `router.py`
3. Agregar rutas en `main.py`
4. Crear frontend en `static/js/modules/`
5. Agregar estilos en `static/css/modules/`

### Agregar Nuevo Proveedor LLM
1. Implementar cliente en `app/llm/service.py`
2. Agregar configuraciÃ³n en `app/config.py`
3. Actualizar detecciÃ³n de proveedor
4. Probar con API key

## ğŸ“ˆ Roadmap

### PrÃ³ximas Funcionalidades
- [ ] **Extraction Module**: ExtracciÃ³n de campos estructurados
- [ ] **Documents Module**: Procesamiento de PDF, Word, Excel
- [ ] **Classification Module**: ClasificaciÃ³n de texto
- [ ] **Sentiment Module**: AnÃ¡lisis de sentimientos
- [ ] **GrÃ¡ficos Interactivos**: VisualizaciÃ³n de resultados
- [ ] **Historial**: Guardar comparaciones anteriores
- [ ] **Export**: Exportar resultados a PDF/Excel

### Mejoras TÃ©cnicas
- [ ] **Caching**: Redis para cache de resultados
- [ ] **Database**: PostgreSQL para persistencia
- [ ] **Authentication**: Sistema de usuarios
- [ ] **Rate Limiting**: LÃ­mites de uso por usuario
- [ ] **Monitoring**: MÃ©tricas y alertas

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **FastAPI** - Framework web moderno y rÃ¡pido
- **OpenAI** - Modelos GPT
- **Anthropic** - Modelos Claude
- **Google** - Modelos Gemini
- **Cursor IDE** - InspiraciÃ³n para el diseÃ±o
- **Stripe** - InspiraciÃ³n para componentes

## ğŸ“ Soporte



---

**Desarrollado con â¤ï¸ para la comunidad de AI/ML**
